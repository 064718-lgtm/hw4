import io
import streamlit as st
import torch
from diffusers import AutoPipelineForText2Image, DPMSolverMultistepScheduler

MODEL_ID = "stabilityai/sd-turbo"


@st.cache_resource(show_spinner=False)
def load_pipeline():
    """Load the lightweight text-to-image pipeline once per session."""
    pipe = AutoPipelineForText2Image.from_pretrained(
        MODEL_ID,
        torch_dtype=torch.float32,
        safety_checker=None,
    )
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
    pipe.set_progress_bar_config(disable=True)
    return pipe.to("cpu")


def generate_image(prompt: str, negative_prompt: str, steps: int, guidance: float, seed: int | None):
    pipe = load_pipeline()
    generator = torch.Generator(device="cpu").manual_seed(seed) if seed is not None else None
    result = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt or None,
        num_inference_steps=steps,
        guidance_scale=guidance,
        generator=generator,
        height=512,
        width=512,
    )
    return result.images[0]


def analyze_prompt_tokens(prompt: str):
    """Approximate per-token importance via encoder embedding norms (avg across SDXL dual encoders when present)."""
    pipe = load_pipeline()
    token_info = []

    def collect(tok, enc):
        inputs = tok(
            prompt,
            padding="max_length",
            truncation=True,
            max_length=tok.model_max_length,
            return_tensors="pt",
        )
        input_ids = inputs.input_ids
        attention_mask = inputs.attention_mask
        with torch.no_grad():
            outputs = enc(input_ids=input_ids, attention_mask=attention_mask)
            hidden = outputs.last_hidden_state  # [1, seq, dim]
            norms = hidden.norm(dim=-1).squeeze(0).cpu().tolist()

        tokens = tok.convert_ids_to_tokens(input_ids[0])
        mask_list = attention_mask[0].tolist()
        for tok_str, norm, mask in zip(tokens, norms, mask_list):
            if mask == 0:
                continue
            if tok_str in ("<pad>", "</s>", "<|endoftext|>"):
                continue
            token_info.append(
                {
                    "token": tok_str,
                    "norm": round(norm, 3),
                }
            )

    try:
        if hasattr(pipe, "tokenizer") and hasattr(pipe, "text_encoder"):
            collect(pipe.tokenizer, pipe.text_encoder)
        if hasattr(pipe, "tokenizer_2") and hasattr(pipe, "text_encoder_2"):
            collect(pipe.tokenizer_2, pipe.text_encoder_2)
    except Exception:
        return []

    # Aggregate by token string (average if duplicated due to dual encoders)
    aggregated = {}
    for item in token_info:
        aggregated.setdefault(item["token"], []).append(item["norm"])
    rows = []
    for tok, norms in aggregated.items():
        rows.append({"token": tok, "avg_norm": round(sum(norms) / len(norms), 3)})
    rows.sort(key=lambda x: x["avg_norm"], reverse=True)
    return rows


st.set_page_config(page_title="Diffusers æ–‡ç”Ÿåœ– (sd-turbo)", page_icon="ğŸ¨", layout="wide")
st.title("Diffusers æ–‡ç”Ÿåœ– (sd-turbo)")
st.caption("è¼•é‡åŒ– Stable Diffusion Turboï¼šä¸­æ–‡ä»‹é¢ã€ç¯„ä¾‹åœ–ç‰‡èˆ‡å¿«é€Ÿç”Ÿæˆã€‚")

tabs = st.tabs(["ğŸ–¼ï¸ ç”Ÿæˆåœ–ç‰‡", "ğŸ“„ ç¯„ä¾‹èªªæ˜"])

with tabs[0]:
    st.markdown(
        """
**ä½¿ç”¨èªªæ˜ï¼ˆä¸­æ–‡ï¼‰ï¼š**
- è¼¸å…¥æƒ³è¦ç”Ÿæˆçš„æè¿°ï¼ˆPromptï¼‰ï¼Œå¯ç”¨ä¸­æ–‡æˆ–è‹±æ–‡ã€‚
- å¯å¡«å¯«ã€Œåå‘æç¤ºã€é¿å…å‡ºç¾çš„å…ƒç´ ï¼Œå¦‚ã€Œä½ç•«è³ªã€æ¨¡ç³Šã€ã€‚
- sd-turbo å»ºè­°æ­¥æ•¸ 1-4ã€Guidance 0-1ï¼Œè§£æåº¦å›ºå®š 512x512 ä»¥é©æ‡‰ Streamlit Cloud CPUã€‚
- é¦–æ¬¡å•Ÿå‹•éœ€ä¸‹è¼‰æ¨¡å‹ï¼Œè«‹ç¨å€™ã€‚
"""
    )

    with st.form("generator"):
        prompt = st.text_area(
            "ä¸»è¦æç¤ºè©ï¼ˆPromptï¼‰",
            value="A cozy reading nook beside a window with soft morning light, watercolor style",
            height=100,
            help="æè¿°ä½ æƒ³è¦çš„ç•«é¢ï¼Œå¯ä»¥ä½¿ç”¨ä¸­æ–‡æˆ–è‹±æ–‡ã€‚",
        )
        negative_prompt = st.text_input(
            "åå‘æç¤ºï¼ˆé¿å…å‡ºç¾ï¼‰", placeholder="ä½ç•«è³ª, æ¨¡ç³Š, noisy", help="åˆ—å‡ºä¸å¸Œæœ›å‡ºç¾çš„å…ƒç´ ï¼Œé€—è™Ÿåˆ†éš”ã€‚"
        )

        col1, col2, col3 = st.columns(3)
        with col1:
            steps = st.slider(
                "ç”Ÿæˆæ­¥æ•¸ï¼ˆInference stepsï¼‰",
                min_value=1,
                max_value=8,
                value=4,
                help="sd-turbo é©åˆ 1-4 æ­¥ï¼Œæ­¥æ•¸è¶Šé«˜ä¸ä¸€å®šæ›´å¥½ã€‚",
            )
        with col2:
            guidance = st.slider(
                "å¼•å°å¼·åº¦ï¼ˆGuidance scaleï¼‰",
                min_value=0.0,
                max_value=5.0,
                value=0.0,
                step=0.1,
                help="å»ºè­° 0-1ï¼›æ•¸å€¼è¶Šå¤§è¶Šè²¼åˆæç¤ºï¼Œä½†å¯èƒ½å‡ºç¾ç‘•ç–µã€‚",
            )
        with col3:
            seed_text = st.text_input("éš¨æ©Ÿç¨®å­ï¼ˆå¯ç•™ç©ºï¼‰", placeholder="ç•™ç©ºå‰‡éš¨æ©Ÿ", help="è¼¸å…¥æ•´æ•¸ä»¥åˆ©é‡ç¾ï¼Œç•™ç©ºç‚ºéš¨æ©Ÿã€‚")

        generate_clicked = st.form_submit_button("ç”Ÿæˆåœ–ç‰‡", use_container_width=True)

    if generate_clicked:
        if not prompt.strip():
            st.warning("è«‹è¼¸å…¥æç¤ºè©ï¼ˆPromptï¼‰ã€‚")
        else:
            seed_value = None
            if seed_text.strip():
                try:
                    seed_value = int(seed_text.strip())
                except ValueError:
                    st.error("éš¨æ©Ÿç¨®å­éœ€ç‚ºæ•´æ•¸ã€‚")
            if seed_text.strip() == "" or seed_value is not None:
                with st.spinner("ç”Ÿæˆä¸­ï¼Œè«‹ç¨å€™..."):
                    try:
                        image = generate_image(prompt.strip(), negative_prompt.strip(), steps, guidance, seed_value)
                        st.image(image, caption="ç”Ÿæˆçµæœï¼ˆsd-turboï¼‰", use_column_width=True)

                        buffer = io.BytesIO()
                        image.save(buffer, format="PNG")
                        st.download_button(
                            label="ä¸‹è¼‰ PNG",
                            data=buffer.getvalue(),
                            file_name="generated.png",
                            mime="image/png",
                            use_container_width=True,
                        )

                        st.subheader("Prompt Token é‡è¦æ€§ï¼ˆåµŒå…¥å‘é‡å¼·åº¦è¿‘ä¼¼ï¼‰")
                        st.caption("ä»¥ä¸‹ç‚º text encoder è¼¸å‡ºå‘é‡çš„ L2 ç¯„æ•¸å¹³å‡å€¼ï¼Œåƒ…ä½œç‚ºç›¸å°é‡è¦æ€§åƒè€ƒã€‚")
                        token_rows = analyze_prompt_tokens(prompt.strip())
                        if token_rows:
                            st.dataframe(token_rows, use_container_width=True)
                        else:
                            st.info("ç„¡æ³•å–å¾— token é‡è¦æ€§ï¼ˆå¯èƒ½æ˜¯æ¨¡å‹æˆ–ç’°å¢ƒä¸æ”¯æ´ï¼‰ã€‚")
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±æ•—ï¼š{e}")

with tabs[1]:
    st.markdown(
        """
**ç¯„ä¾‹æµç¨‹ï¼ˆExample Walkthroughï¼‰ï¼š**
- ç¯„ä¾‹ 1ï¼š
  - ä¸»è¦æç¤ºè©ï¼š`A cozy reading nook beside a window with soft morning light, watercolor style`
  - åå‘æç¤ºï¼š`ä½ç•«è³ª, æ¨¡ç³Š, noisy`
  - å»ºè­°æ­¥æ•¸ï¼š4ï¼Œå»ºè­°å¼•å°ï¼š0.5
- ç¯„ä¾‹ 2ï¼š
  - ä¸»è¦æç¤ºè©ï¼š`firework with rainbow`
  - åå‘æç¤ºï¼š`ä½ç•«è³ªï¼Œæ¨¡ç³Šï¼Œblur`
  - å»ºè­°æ­¥æ•¸ï¼š4ï¼Œå»ºè­°å¼•å°ï¼š0.3
"""
    )
    st.image("example.png", caption="example.png ç¯„ä¾‹ 1 è¼¸å‡ºç¤ºæ„", use_column_width=True)
    st.image("example2.png", caption="example2.png ç¯„ä¾‹ 2 è¼¸å‡ºç¤ºæ„", use_column_width=True)
    st.info("é¦–æ¬¡å•Ÿå‹•æœƒä¸‹è¼‰æ¨¡å‹ï¼Œè‹¥ç­‰å¾…è¼ƒä¹…å±¬æ­£å¸¸ç¾è±¡ã€‚è‹¥éœ€å…§å®¹éæ¿¾ï¼Œè«‹å•Ÿç”¨å®‰å…¨æª¢æŸ¥æˆ–å¦è¡ŒåŠ ä¸Šå¯©æ ¸ã€‚")
